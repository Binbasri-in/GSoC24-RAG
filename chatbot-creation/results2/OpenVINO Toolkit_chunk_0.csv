idea title,idea description,skills,difficulty,duration
OpenVINO Extension for Automatic1111 Stable Diffusion WebUI,"Automatic1111 is a powerful web user interface based on Gradio library specifically designed for Stable Diffusion. It's most popular open-source Stable Diffusion WebUI on GitHub with 119K+ stars, which supports a lot of features like text-to-image, image-to-image, inpainting, Lora models, custom models from model hubs like civitai.com and huggingface etc. OpenVINO support for Automatic1111 enables Stable Diffusion run on Intel CPUs and GPUs, this solution is currently supported using a custom script. Implementing OpenVINO through the Automatic1111 extension will provide an easier way to use OpenVINO. This project will also aim to provide support for more AUTOMATIC111 features with OpenVINO.","Python, good understanding of Stable diffusion architectures, experience with Hugging Face and Diffusers libraries, experience with PyTorch (OpenVINO is a plus), Git",Medium to hard,350 hours
Inference of Neural model in Node.js environment using OpenVINO,"There is a new OpenVINO NPM package. You can work with a neural model directly from your Node.js application now. We propose to rework existing samples that use Python API to Node.js API, or even implement new examples using VINO JS API.","JavaScript, Node.js, Python",Easy to medium,90 hours
Desktop Chat-Bot application,Neural Language Model can work locally without the internet. You will write your own Chatbot desktop cross-platform application using OpenVINO and Electron (or analogs). The Chatbot may be general or crafted to your needs (subject to the NLP model).,"JavaScript, Electron",Medium,175 hours
Add Image-to-Image and Image-to-Text generation with GUI support for OpenVINO GenAI,"Currently, openvino.genai has C++ image generation pipeline with Stable Diffusion and LCM, but only Text-to-Image is supported. This project would add Image-to-Image generation and Image-to-Text generation support with C++ cross platform GUI.","C++ programming, knowledge of PyTorch and Qt Creator",Medium,175 hours
OpenVINO CPU plugin functional test cases WASM enablement,"OpenVINO has supported WASM build, but there are hundreds of thousands of CPU plugin functional test cases that cannot run based on WASM build due to there are many native issues that need to be resolved, such as multi-threads, local file access, dynamic libraries, memory sharing. We propose talents to participate in this activity to enable more WASM tests of the OpenVINO CPU plugin.","C++, JS, WASM and Emscripten",Medium to hard,350 hours
OpenVINO Conditional Compilation improvement,"OpenVINO adopts conditional compilation to optimize package binaries size, which has achieved considerable binarie size reduction. But conditional compilation has a limitation - it is device dependent, that to say the conditional compilation packages generated in one CPU platform cannot always run on another different CPU platform. We encourage talents to research a solution to support device agnostic condition compilation (permit slight binaries size increase), which can support the conditional compilation packages generated in one CPU platform and can run on other Intel CPU platforms.",C++,Medium,175 hours
OpenVINO adapters - PyTorch adapter,"OpenVINO adapters' goal is to provide a lightweight layer of Python code that enables easy switching between already used framework (PyTorch) and OpenVINO - targeting inference purposes. The goal is to showcase the potential performance benefits of using OV. The change on the user side should look like import torch --> import openvino_adapters.torch and ... that's it! (maybe some minor changes like excluding cuda() calls:)) The project includes the whole development cycle: creating POC, productization of the solution, adding tests, making an installable package, and creating documentation.","Python, PyTorch knowledge",Medium to hard,175 hours
Improve Generative AI workload performance on ARM devices with OpenVINO,"The goal of this project is to implement set of optimizations inside OpenVINO runtime which target GenAI models (e.g. text-generation, diffusers). Optimizations should include improvements in terms of latency/throughput metrics, faster model compilation time and lower memory consumption.","Mac device with M1/M2/M3 chip is a must, C++",Medium,350 hours
NNCF Quantization Analytics Tool,"Quantization, a widely adopted technique for reducing model size and accelerating model inference, often leads to a slight decrease in accuracy compared to the original floating-point model. However, in some cases, quantization can introduce significant performance degradation. Identifying the root cause of these accuracy drops can be a difficult task, and often even more challenging than fixing it. In this project, we will develop an analytic tool for analyzing quantization errors in the quantized models using NNCF. We will provide a user-friendly interface for inspecting quantization errors, calculating statistics and metrics such as MSE, and SQNR to identify the layers with the most significant errors, and visualizing them together with the model in Netron. We will also create a tutorial with recommendations for optimizing the quantization process to improve model accuracy based on collected analytics.","DL basics, understanding of ML model optimization, Python programming",Medium,350 hours
Accelerating PyTorch Lightning and ComfyUI with torch.compile OpenVINO,"The goal of this project to accelerate pytorch-based frameworks like PyTorch Lightning and ComfyUI by leveraging torch.compile OpenVINO backend. PyTorch Lightning provides a structured and modular framework for developing deep learning models, particularly tailored for tasks such as image classification, natural language processing, and reinforcement learning. ComfyUI is a popular stable diffusion WebUI framework for image generation workflows. In this project, you will create optimized PyTorch Lightning Modules and ComfyUI Stable diffusion models by utilizing torch.compile OpenVINO backend for inference. Optimized models should demonstrate performance improvements on Intel CPUs and GPUs over native PyTorch execution.","Python, C++, PyTorch. Good to have: OpenVINO, PyTorch Lightning, Stable Diffusion, torch.compile feature",Medium to hard,350 hours
PyTorch Model Optimizations with torch.compile OpenVINO Backend,"The goal of this project is to enhance the compatibility and performance of popular deep learning models with the OpenVINO backend in torch.compile. Specifically, the focus will be on enabling four diverse models: Omni3D, AudioCraft, LLaVA and Code Llama. The project involves identifying and handling unsupported operations within these models, implementing necessary operations, and ensuring accuracy, all while optimizing performance through thorough testing and benchmarking. A contributing guide is available to facilitate collaboration.","Python, C++, PyTorch. Good to have: OpenVINO, torch.compile feature",Medium to hard,350 hours
Prototype for JAX/Flax Models Support (or Mindspore),"Flax/JAX is a new solution for training models, that provides much faster training than TensorFlow and PyTorch. So we should expect increase in amount of Flax/Jax models. However, OpenVINO currently supports PyTorch, TensorFlow, ONNX, PDPD models but it lacks of native support for JAX models. Not all JAX models can be exported to TensorFlow SavedModel format. So there exists of a problem for native and direct support for JAX models without intermediate format usage. The implemented functionality should include logic for parsing traced JAX objects, translators for conversion basic JAX operations into OpenVINO opset decompositions. The functionality should be relied and inherit common FE API so that it will be possible to convert JAX models using ovc.convert_model. The feature should be extendable in the future by others (OV team and open-source community) to support new JAX operations and models. The goal is to implement a prototype with basic functionality to support fundamental models (ResNet, BERT) trained with JAX. As alternative choice, you can consider of adding support for Mindspore framework (https://github.com/mindspore-ai/mindspore) and its MIDIR format support.","Python, C++, JAX, Flax. Good to have: Mindspore",Medium to hard,350 hours
